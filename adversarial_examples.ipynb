{
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cUGQIN7TDugJ"
   ],
   "name": "adversarial_examples.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "colab_type": "text",
      "id": "7Ix6oLLaEadR"
     },
     "source": [
      "Install Pytorch and Torchvision"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
      "!pip install Pillow==5.3.0\n",
      "!pip3 install torchvision\n",
      "# reset runtime to allow new pillow version\n",
      "import os\n",
      "# restart to make sure Colab uses correct Pillow version\n",
      "os.kill(os.getpid(), 9)"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 459
      },
      "colab_type": "code",
      "id": "QUqGT8tSDzk4",
      "outputId": "deeed561-fa61-4ba8-b1d2-74c9521cf632"
     },
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "colab_type": "text",
      "id": "w6kbZpFjS5Jv"
     },
     "source": [
      "Open Google Drive"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from google.colab import drive\n",
      "drive.mount('/content/drive')\n",
      "%cd drive/My Drive/Masterproef/pytorch-yolo2"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 147
      },
      "colab_type": "code",
      "id": "Nj0e4ZH0S3su",
      "outputId": "b5cd5b03-6475-4c9b-c405-f2c1ddf3da97"
     },
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "colab_type": "text",
      "id": "G8gJrhY5UEIt"
     },
     "source": [
      "Import library"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import PIL\n",
      "print(PIL.PILLOW_VERSION)\n",
      "import load_data"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 72
      },
      "colab_type": "code",
      "id": "IgJH1GsEUH2p",
      "outputId": "e07bb195-1a17-49a9-c686-5927e44b86be"
     },
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "colab_type": "text",
      "id": "pQJVwnBwWFQp"
     },
     "source": [
      "# Run my code (op subset van 100 INRIA dataset)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "colab_type": "text",
      "id": "mAhpOAfODY68"
     },
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from load_data import *\n",
      "import load_data\n",
      "import gc\n",
      "import matplotlib.pyplot as plt\n",
      "from torch import autograd\n",
      "plt.rcParams[\"axes.grid\"] = False\n",
      "plt.axis('off')\n",
      "\n",
      "img_dir = \"inria/Train/pos\"\n",
      "lab_dir = \"inria/Train/pos/yolo-labels\"\n",
      "cfgfile = \"cfg/yolo.cfg\"\n",
      "weightfile = \"weights/yolo.weights\"\n",
      "printfile = \"non_printability/30values.txt\"\n",
      "patch_size = 300\n",
      "\n",
      "print('LOADING MODELS')\n",
      "darknet_model = Darknet(cfgfile)\n",
      "darknet_model.load_weights(weightfile)\n",
      "darknet_model = darknet_model.eval().cuda()\n",
      "patch_applier = PatchApplier().cuda()\n",
      "patch_transformer = PatchTransformer().cuda()\n",
      "prob_extractor = MaxProbExtractor(0, 80).cuda()\n",
      "nps_calculator = NPSCalculator(printfile, patch_size)\n",
      "nps_calculator = nps_calculator.cuda()\n",
      "total_variation = TotalVariation().cuda()\n",
      "print('MODELS LOADED')"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 388
      },
      "colab_type": "code",
      "id": "a_HzCgNoDSyP",
      "outputId": "afe61129-2d3b-43f5-fc8e-8b3d591bf2eb"
     },
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img_size = darknet_model.height\n",
      "batch_size = 6#10#18\n",
      "n_epochs = 10000\n",
      "max_lab = 14\n",
      "\n",
      "# Choose between initializing with gray or random\n",
      "adv_patch_cpu = torch.full((3,patch_size,patch_size),0.5)\n",
      "#adv_patch_cpu = torch.rand((3,patch_size,patch_size))\n",
      "\n",
      "\n",
      "patch_img = Image.open(\"saved_patches/patchnew0.jpg\").convert('RGB')\n",
      "tf = transforms.Resize((patch_size,patch_size))\n",
      "patch_img = tf(patch_img)\n",
      "tf = transforms.ToTensor()\n",
      "adv_patch_cpu = tf(patch_img)\n",
      "\n",
      "adv_patch_cpu.requires_grad_(True)\n",
      "\n",
      "\n",
      "print('INITIALIZING DATALOADER')\n",
      "train_loader = torch.utils.data.DataLoader(InriaDataset(img_dir, lab_dir, max_lab, img_size, shuffle=True),\n",
      "                                              batch_size=batch_size,\n",
      "                                              shuffle=True,\n",
      "                                              num_workers=10)\n",
      "print('DATALOADER INITIALIZED')\n",
      "\n",
      "optimizer = optim.Adam([adv_patch_cpu], lr=.03, amsgrad=True)\n",
      "\n",
      "#try: \n",
      "et0 = time.time()\n",
      "for epoch in range(n_epochs):\n",
      "    ep_det_loss = 0\n",
      "    bt0 = time.time()\n",
      "    for i_batch, (img_batch, lab_batch) in enumerate(train_loader):\n",
      "        with autograd.detect_anomaly():\n",
      "            img_batch = img_batch.cuda()\n",
      "            lab_batch = lab_batch.cuda()\n",
      "            #print('TRAINING EPOCH %i, BATCH %i'%(epoch, i_batch))\n",
      "            adv_patch = adv_patch_cpu.cuda()\n",
      "            adv_batch_t = patch_transformer(adv_patch, lab_batch, img_size, do_rotate=True)\n",
      "            p_img_batch = patch_applier(img_batch, adv_batch_t)\n",
      "            p_img_batch = F.interpolate(p_img_batch,(darknet_model.height, darknet_model.width))\n",
      "            output = darknet_model(p_img_batch)\n",
      "            max_prob = prob_extractor(output)\n",
      "            nps = nps_calculator(adv_patch)\n",
      "            tv = total_variation(adv_patch)\n",
      "\n",
      "            det_loss = torch.mean(max_prob)\n",
      "            ep_det_loss += det_loss.detach().cpu().numpy()\n",
      "            '''\n",
      "            nps_loss = nps\n",
      "            tv_loss = tv*8\n",
      "            loss = nps_loss + (det_loss**3/tv_loss + tv_loss**3/det_loss)**(1/3)\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            optimizer.zero_grad()\n",
      "            adv_patch_cpu.data.clamp_(0,1)       #keep patch in image range\n",
      "\n",
      "            '''\n",
      "            nps_loss = nps*0.01\n",
      "            tv_loss = tv*2.5\n",
      "            loss = det_loss + nps_loss + tv_loss\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            optimizer.zero_grad()\n",
      "            adv_patch_cpu.data.clamp_(0,1)       #keep patch in image range\n",
      "            \n",
      "            bt1 = time.time()\n",
      "            if i_batch%5 == 0:\n",
      "                print('BATCH', i_batch, end='...\\n')\n",
      "                im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
      "                plt.imshow(im)\n",
      "                plt.show()\n",
      "            '''\n",
      "            print('  BATCH NR: ', i_batch)\n",
      "            print('BATCH LOSS: ', loss.detach().cpu().numpy())\n",
      "            print('  DET LOSS: ', det_loss.detach().cpu().numpy())\n",
      "            print('  NPS LOSS: ', nps_loss.detach().cpu().numpy())\n",
      "            print('   TV LOSS: ', tv_loss.detach().cpu().numpy())\n",
      "            print('BATCH TIME: ', bt1-bt0)\n",
      "            '''\n",
      "            if i_batch + 1 >= len(train_loader):\n",
      "                print('\\n')\n",
      "            else:\n",
      "                del adv_batch_t, output, max_prob, det_loss, p_img_batch, nps_loss, tv_loss, loss\n",
      "                torch.cuda.empty_cache()\n",
      "            bt0 = time.time()\n",
      "    et1 = time.time()\n",
      "    ep_det_loss = ep_det_loss/len(train_loader)\n",
      "    ep_nps_loss = nps_loss.detach().cpu().numpy()\n",
      "    ep_tv_loss = tv_loss.detach().cpu().numpy()\n",
      "    tot_ep_loss = ep_det_loss + ep_nps_loss + ep_tv_loss\n",
      "    if True:\n",
      "        print('  EPOCH NR: ', epoch),\n",
      "        print('EPOCH LOSS: ', tot_ep_loss)\n",
      "        print('  DET LOSS: ', ep_det_loss)\n",
      "        print('  NPS LOSS: ', ep_nps_loss)\n",
      "        print('   TV LOSS: ', ep_tv_loss)\n",
      "        print('EPOCH TIME: ', et1-et0)\n",
      "        im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
      "        plt.imshow(im)\n",
      "        plt.show()\n",
      "        im.save(\"saved_patches/patchnew1.jpg\")\n",
      "        del adv_batch_t, output, max_prob, det_loss, p_img_batch, nps_loss, tv_loss, loss\n",
      "        torch.cuda.empty_cache()\n",
      "    et0 = time.time()\n",
      "\n",
      "#except RuntimeError:\n",
      "#    torch.cuda.empty_cache()\n",
      "#    print('cuda refreshed')"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 42752
      },
      "colab_type": "code",
      "id": "PW1mdISbWEt4",
      "outputId": "f9c205e6-9ede-4c48-cd44-c5e018cbeb3d"
     },
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "colab_type": "text",
      "id": "cUGQIN7TDugJ"
     },
     "source": [
      "Run my code (obsolete)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from load_data import *\n",
      "import load_data\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams[\"axes.grid\"] = False\n",
      "\n",
      "def pad_and_scale(img, lab, imgsize):\n",
      "    \"\"\"\n",
      "\n",
      "    Args:\n",
      "        img:\n",
      "\n",
      "    Returns:\n",
      "\n",
      "    \"\"\"\n",
      "    w,h = img.size\n",
      "    if w==h:\n",
      "        padded_img = img\n",
      "    else:\n",
      "        dim_to_pad = 1 if w<h else 2\n",
      "        if dim_to_pad == 1:\n",
      "            padding = (h - w) / 2\n",
      "            padded_img = Image.new('RGB', (h,h), color=(127,127,127))\n",
      "            padded_img.paste(img, (int(padding), 0))\n",
      "            lab[:, [1]] = (lab[:, [1]] * w + padding) / h\n",
      "            lab[:, [3]] = (lab[:, [3]] * w / h)\n",
      "        else:\n",
      "            padding = (w - h) / 2\n",
      "            padded_img = Image.new('RGB', (w, w), color=(127,127,127))\n",
      "            padded_img.paste(img, (0, int(padding)))\n",
      "            lab[:, [2]] = (lab[:, [2]] * h + padding) / w\n",
      "            lab[:, [4]] = (lab[:, [4]] * h  / w)\n",
      "    padded_img = padded_img.resize((imgsize,imgsize))     #choose here\n",
      "    return padded_img, lab\n",
      "\n",
      "#img_dir = \"inria/Train/pos\"\n",
      "#lab_dir = \"inria/Train/pos/yolo-labels\"\n",
      "\n",
      "img_path = \"test/img/crop001024.png\"\n",
      "lab_path = \"test/lab/crop001024.txt\"\n",
      "\n",
      "#cfgfile = \"cfg/yolov2.cfg\"\n",
      "#weightfile = \"weights/yolov2.weights\"\n",
      "\n",
      "cfgfile = \"cfg/yolo.cfg\"\n",
      "weightfile = \"weights/yolo.weights\"\n",
      "\n",
      "printfile = \"non_printability/30values.txt\"\n",
      "patch_size = 300\n",
      "\n",
      "darknet_model = Darknet(cfgfile)\n",
      "darknet_model.load_weights(weightfile)\n",
      "darknet_model = darknet_model.eval().cuda()\n",
      "patch_applier = PatchApplier().cuda()\n",
      "patch_transformer = PatchTransformer().cuda()\n",
      "prob_extractor = MaxProbExtractor(0, 80).cuda()\n",
      "nps_calculator = NPSCalculator(printfile, patch_size)\n",
      "nps_calculator = nps_calculator.cuda()\n",
      "total_variation = TotalVariation().cuda()\n",
      "\n",
      "imgsize = darknet_model.height\n",
      "image = Image.open(img_path).convert('RGB')\n",
      "label = np.loadtxt(lab_path)\n",
      "label = torch.from_numpy(label).float()\n",
      "if label.dim() == 1:\n",
      "    label = label.unsqueeze(0)\n",
      "image, label = pad_and_scale(image, label, imgsize)\n",
      "transform = transforms.ToTensor()\n",
      "image = transform(image)\n",
      "\n",
      "batch_size = 24    \n",
      "image = image.unsqueeze(0)\n",
      "label = label.unsqueeze(0)\n",
      "img_batch = image.expand(batch_size,-1,-1,-1)\n",
      "lab_batch = label.expand(batch_size,-1,-1)\n",
      "\n",
      "img_batch = img_batch.cuda()\n",
      "lab_batch = lab_batch.cuda()\n",
      "\n",
      "n_epochs = 1000\n",
      "\n",
      "#adv_patch_cpu = torch.full((3,patch_size,patch_size),0.5)\n",
      "adv_patch_cpu = torch.rand((3,patch_size,patch_size))\n",
      "adv_patch_cpu.requires_grad_(True)\n",
      "\n",
      "optimizer = optim.Adam([adv_patch_cpu], lr = 0.01)\n",
      "\n",
      "tl1 = time.time()\n",
      "for epoch in range(n_epochs):\n",
      "    ffw1 = time.time()\n",
      "    adv_patch = adv_patch_cpu.cuda()\n",
      "    tl0 = time.time()\n",
      "    #print('batch load time: ', tl0-tl1)\n",
      "    img_size = img_batch.size(-1)\n",
      "    #print('transforming patches')\n",
      "    t0 = time.time()\n",
      "    adv_batch_t = patch_transformer(adv_patch, lab_batch, img_size)\n",
      "    #print('applying patches')\n",
      "    t1 = time.time()\n",
      "    p_img_batch = patch_applier(img_batch, adv_batch_t)\n",
      "    p_img_batch = F.interpolate(p_img_batch,(darknet_model.height, darknet_model.width))\n",
      "    #print('running patched images through model')\n",
      "    t2 = time.time()\n",
      "\n",
      "    output = darknet_model(p_img_batch)\n",
      "    #print('does output require grad? ',output.requires_grad)\n",
      "    #print('extracting max probs')\n",
      "    t3 = time.time()\n",
      "    max_prob = prob_extractor(output)\n",
      "    #print('does max_prob require grad? ',max_prob.requires_grad)\n",
      "    #print('calculating nps')\n",
      "    t4 = time.time()\n",
      "    nps = nps_calculator(adv_patch)\n",
      "    t5 = time.time()\n",
      "    #print('calculating tv')\n",
      "    tv = total_variation(adv_patch)\n",
      "    t6 = time.time()\n",
      "    '''\n",
      "    print('---------------------------------')\n",
      "    print('   patch transformation : %f' % (t1-t0))\n",
      "    print('      patch application : %f' % (t2-t1))\n",
      "    print('        darknet forward : %f' % (t3-t2))\n",
      "    print(' probability extraction : %f' % (t4-t3))\n",
      "    print('        nps calculation : %f' % (t5-t4))\n",
      "    print('        total variation : %f' % (t6-t5))\n",
      "    print('---------------------------------')\n",
      "    print('     total forward pass : %f' % (t6-t0))\n",
      "\n",
      "    print(torch.mean(max_prob))\n",
      "    print(nps)\n",
      "    print(tv)\n",
      "    '''\n",
      "\n",
      "    det_loss = torch.mean(max_prob)\n",
      "    nps_loss = nps*0.1\n",
      "    tv_loss = tv*0.00005\n",
      "    loss = det_loss + nps_loss + tv_loss\n",
      "\n",
      "    #img_batch.retain_grad()\n",
      "    #adv_batch_t.retain_grad()\n",
      "    #adv_patch.retain_grad()\n",
      "\n",
      "    #print('loss to patch', torch.autograd.grad(loss,img_batch))\n",
      "    loss.backward()\n",
      "    tl1 = time.time()\n",
      "    #print('adv_patch.grad',adv_patch_cpu.grad)\n",
      "    #print('adv_batch_t.grad',adv_batch_t.grad)\n",
      "    #print('img_batch.grad',img_batch.grad)\n",
      "    optimizer.step()\n",
      "    optimizer.zero_grad()\n",
      "    torch.cuda.empty_cache()\n",
      "    ffw2 = time.time()\n",
      "    if (epoch)%5 == 0:\n",
      "        print('  EPOCH NR: ', epoch)\n",
      "        print('EPOCH LOSS: ', loss.detach().cpu().numpy())\n",
      "        print('  DET LOSS: ', det_loss.detach().cpu().numpy())\n",
      "        print('  NPS LOSS: ', nps_loss.detach().cpu().numpy())\n",
      "        print('   TV LOSS: ', tv_loss.detach().cpu().numpy())\n",
      "        print('EPOCH TIME: ', ffw2-ffw1)\n",
      "        im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
      "        plt.imshow(im)\n",
      "        plt.show()\n",
      "    del adv_batch_t, output, max_prob\n"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 15150
      },
      "colab_type": "code",
      "id": "DJoz8fas_cK9",
      "outputId": "ab442c87-5b22-4871-d73d-0f4860ee7190"
     },
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "colab_type": "text",
      "id": "6F3NC7IVsWMY"
     },
     "source": [
      "Check if our patch fools the detector"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import *\n",
      "patch_size = 300\n",
      "img_size = darknet_model.height\n",
      "\n",
      "img_dir_v = \"inria/Test/pos\"\n",
      "lab_dir_v = \"inria/Test/pos/yolo-labels\"\n",
      "\n",
      "adv_patch = Image.open(\"saved_patches/patch11.jpg\").convert('RGB')\n",
      "transform = transforms.ToTensor()\n",
      "adv_patch = transform(adv_patch).cuda()\n",
      "\n",
      "\n",
      "train_loader = torch.utils.data.DataLoader(InriaDataset(img_dir_v, lab_dir_v, 14, img_size, shuffle=True),\n",
      "                                              batch_size=1,\n",
      "                                              shuffle=True,\n",
      "                                              num_workers=10)\n",
      "\n",
      "for i_batch, (img_batch, lab_batch) in enumerate(train_loader):\n",
      "    img_size = img_batch.size(-1)\n",
      "    adv_batch_t = patch_transformer(adv_patch, lab_batch.cuda(), img_size, do_rotate=True, rand_loc=False)\n",
      "    p_img = patch_applier(img_batch.cuda(), adv_batch_t)\n",
      "    p_img = F.interpolate(p_img,(darknet_model.height, darknet_model.width))\n",
      "    output = darknet_model(p_img)\n",
      "    boxes = get_region_boxes(output,0.5,darknet_model.num_classes, \n",
      "                         darknet_model.anchors, darknet_model.num_anchors)[0]\n",
      "    boxes = nms(boxes,0.4)\n",
      "    class_names = load_class_names('data/coco.names')\n",
      "    squeezed = p_img.squeeze(0)\n",
      "    print(squeezed.shape)\n",
      "    img = transforms.ToPILImage('RGB')(squeezed.detach().cpu())\n",
      "    plotted_image = plot_boxes(img, boxes, class_names=class_names)\n",
      "    plt.imshow(plotted_image)\n",
      "    plt.show()\n",
      "'''\n",
      "# apply an image as patch\n",
      "patch_size = adv_patch.size(-1)\n",
      "horse = Image.open(\"data/horse.jpg\").convert('RGB')\n",
      "tf = transforms.Resize((patch_size,patch_size))\n",
      "horse = tf(horse)\n",
      "transform = transforms.ToTensor()\n",
      "horse = transform(horse)\n",
      "\n",
      "adv_batch_t = patch_transformer(horse.cuda(), label.cuda(), img_size)\n",
      "p_img = patch_applier(image.cuda(), adv_batch_t)\n",
      "p_img = F.interpolate(p_img,(darknet_model.height, darknet_model.width))\n",
      "output = darknet_model(p_img)\n",
      "boxes = get_region_boxes(output,0.5,darknet_model.num_classes, \n",
      "                         darknet_model.anchors, darknet_model.num_anchors)[0]\n",
      "boxes = nms(boxes,0.4)\n",
      "class_names = load_class_names('data/coco.names')\n",
      "squeezed = p_img.squeeze(0)\n",
      "im = transforms.ToPILImage('RGB')(squeezed.detach().cpu())\n",
      "plotted_image = plot_boxes(im, boxes, class_names=class_names)\n",
      "plt.imshow(plotted_image)\n",
      "plt.show()\n",
      "'''\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {
      "colab": {
       "base_uri": "https://localhost:8080/",
       "height": 123246
      },
      "colab_type": "code",
      "id": "nhvMDkdFUJ8q",
      "outputId": "29eb07df-ef5b-4a7a-b778-a91a67363b5c"
     },
     "outputs": [],
     "prompt_number": 0
    }
   ],
   "metadata": {}
  }
 ]
}